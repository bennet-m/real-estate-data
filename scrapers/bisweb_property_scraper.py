from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
from .base_scraper import BaseScraper


class BISWEBPropertyScraper(BaseScraper):
    """Scraper for BISWEB Property Profile Overview page to extract landmark status, additional BINs, and violations"""
    
    def _scrape_data(self, driver, wait):
        """Scrape building data from BISWEB Property Profile Overview page"""
        print("üè¢ Scraping BISWEB Property Profile Overview data...")
        
        # Wait for page to be in ready state
        print("  ‚è≥ Waiting for page to load...")
        wait.until(lambda d: d.execute_script("return document.readyState") == "complete")
        
        # Wait a bit more for dynamic content to start loading
        time.sleep(2)
        
        building_data = {}
        
        # Scrape Landmark Status
        try:
            print("  ‚è≥ Looking for Landmark Status row...")
            # Find the row containing "Landmark Status:"
            landmark_row = wait.until(
                EC.presence_of_element_located(
                    (By.XPATH, "//tr[td[@class='content' and contains(., 'Landmark Status:')]]")
                )
            )
            
            # Get all cells in this row
            cells = landmark_row.find_elements(By.CSS_SELECTOR, "td.content")
            
            # The landmark status value should be in the second cell (index 1)
            if len(cells) >= 2:
                landmark_status = self.get_element_text(cells[1])
                if landmark_status:
                    building_data["Landmark Status"] = landmark_status
                    print(f"  üìä Landmark Status: {landmark_status}")
        except Exception as e:
            print(f"  ‚ö†Ô∏è Error extracting Landmark Status: {str(e)}")
        
        # Scrape Additional BINs
        try:
            print("  ‚è≥ Looking for Additional BINs row...")
            # Find the row containing "Additional BINs for Building:"
            bins_row = wait.until(
                EC.presence_of_element_located(
                    (By.XPATH, "//tr[td[@class='content' and contains(., 'Additional BINs for Building:')]]")
                )
            )
            
            # Get all cells in this row
            cells = bins_row.find_elements(By.CSS_SELECTOR, "td.content")
            
            # The additional BINs value should be in the second cell (index 1)
            if len(cells) >= 2:
                bins_text = self.get_element_text(cells[1])
                
                # Clean up the text - remove any extra whitespace and newlines
                bins_text = ' '.join(bins_text.split())
                
                if bins_text and bins_text.upper() != "NONE":
                    building_data["Additional BINs"] = bins_text
                    print(f"  üìä Additional BINs: {bins_text}")
                else:
                    building_data["Additional BINs"] = "NONE"
                    print(f"  üìä Additional BINs: NONE")
        except Exception as e:
            print(f"  ‚ö†Ô∏è Error extracting Additional BINs: {str(e)}")
        
        # Scrape DOB Violations
        try:
            print("  ‚è≥ Looking for DOB Violations row...")
            # Find the row containing "Violations-DOB" link
            dob_violations_row = wait.until(
                EC.presence_of_element_located(
                    (By.XPATH, "//tr[td[@class='content']//a[contains(@href, 'ActionsByLocationServlet') and contains(., 'Violations-DOB')]]")
                )
            )
            
            # Get all cells in this row
            cells = dob_violations_row.find_elements(By.CSS_SELECTOR, "td.content")
            
            # Second cell (index 1) is total, third cell (index 2) is open
            if len(cells) >= 3:
                total_dob = self.get_element_text(cells[1])
                open_dob = self.get_element_text(cells[2])
                
                if total_dob:
                    building_data["DOB Violations Total"] = total_dob
                    print(f"  üìä DOB Violations Total: {total_dob}")
                if open_dob:
                    building_data["DOB Violations Open"] = open_dob
                    print(f"  üìä DOB Violations Open: {open_dob}")
        except Exception as e:
            print(f"  ‚ö†Ô∏è Error extracting DOB Violations: {str(e)}")
        
        # Scrape ECB Violations
        try:
            print("  ‚è≥ Looking for ECB Violations row...")
            # Find the row containing "Violations-OATH/ECB" link
            ecb_violations_row = wait.until(
                EC.presence_of_element_located(
                    (By.XPATH, "//tr[td[@class='content']//a[contains(@href, 'ECBQueryByLocationServlet') and contains(., 'Violations-OATH/ECB')]]")
                )
            )
            
            # Get all cells in this row
            cells = ecb_violations_row.find_elements(By.CSS_SELECTOR, "td.content")
            
            # Second cell (index 1) is total, third cell (index 2) is open
            if len(cells) >= 3:
                total_ecb = self.get_element_text(cells[1])
                open_ecb = self.get_element_text(cells[2])
                
                if total_ecb:
                    building_data["ECB Violations Total"] = total_ecb
                    print(f"  üìä ECB Violations Total: {total_ecb}")
                if open_ecb:
                    building_data["ECB Violations Open"] = open_ecb
                    print(f"  üìä ECB Violations Open: {open_ecb}")
        except Exception as e:
            print(f"  ‚ö†Ô∏è Error extracting ECB Violations: {str(e)}")
        
        return building_data

